{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35280225-3a17-4ed5-9c34-40eea0f6fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f59d8d44-ce7f-4d6d-8af2-0b10ae3999c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    def __init__(self, dim_in, dim_lowrank, dim_hidden, num_blocks):\n",
    "        super(Controller, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_lowrank = dim_lowrank\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.num_blocks = num_blocks\n",
    "        assert self.dim_hidden % self.num_blocks == 0, \"hidden vector must be divisible into N blocks\"\n",
    "        self.U = nn.Linear(dim_in, dim_lowrank, bias = False)\n",
    "        self.V = nn.Linear(dim_lowrank, dim_hidden, bias = False)\n",
    "    def forward(self, x):\n",
    "        logits = self.V(self.U(x))\n",
    "        original_shape = logits.shape\n",
    "        logits = logits.reshape(*logits.shape[:-1], self.num_blocks, self.dim_hidden // self.num_blocks)\n",
    "        if self.training:\n",
    "            mask = F.gumbel_softmax(logits, tau=0.1, hard=True)\n",
    "            return mask.reshape(original_shape)\n",
    "        else:\n",
    "            selected = torch.argmax(logits, dim=-1)\n",
    "            mask = F.one_hot(selected, num_classes = self.dim_hidden // self.num_blocks)\n",
    "            return mask.reshape(original_shape)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "298823f7-33a8-42f4-921e-cc472b4dfb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[7.3692e-01, 7.9813e-01, 5.0458e-01, 5.3212e-01],\n",
      "          [5.1928e-01, 1.1359e-01, 9.7737e-01, 6.4920e-01],\n",
      "          [6.8741e-01, 4.5131e-01, 1.5995e-01, 8.3960e-01]],\n",
      "\n",
      "         [[5.4992e-01, 7.4053e-04, 1.3080e-01, 5.8648e-01],\n",
      "          [7.3517e-01, 5.8267e-01, 9.2709e-01, 6.9977e-01],\n",
      "          [7.9869e-01, 1.7985e-02, 3.0743e-01, 8.6149e-01]],\n",
      "\n",
      "         [[2.7280e-01, 6.8720e-01, 8.7931e-01, 6.1018e-01],\n",
      "          [1.7987e-02, 6.3314e-01, 3.6387e-02, 8.4156e-01],\n",
      "          [2.3171e-01, 3.3489e-02, 8.5126e-01, 8.1929e-01]],\n",
      "\n",
      "         [[3.5983e-01, 4.8006e-01, 9.2413e-01, 7.2229e-01],\n",
      "          [1.8599e-02, 5.9205e-02, 1.5740e-02, 1.5232e-01],\n",
      "          [3.7424e-01, 6.5595e-01, 4.5042e-01, 2.0002e-01]],\n",
      "\n",
      "         [[6.4676e-01, 7.0073e-01, 4.3187e-01, 4.0098e-01],\n",
      "          [4.7939e-01, 3.3698e-01, 1.3873e-01, 1.9097e-01],\n",
      "          [9.3650e-01, 7.9411e-01, 8.3972e-01, 4.2133e-01]]],\n",
      "\n",
      "\n",
      "        [[[7.9493e-01, 5.3347e-01, 1.3234e-01, 2.0028e-01],\n",
      "          [2.2333e-01, 8.0899e-01, 9.1624e-01, 3.1892e-01],\n",
      "          [2.0566e-01, 7.6405e-01, 6.8178e-01, 2.5958e-01]],\n",
      "\n",
      "         [[9.2316e-01, 8.5274e-01, 2.4136e-01, 9.7465e-01],\n",
      "          [6.5408e-01, 8.0436e-01, 7.8910e-02, 2.5283e-02],\n",
      "          [2.6665e-01, 8.4579e-02, 5.5514e-01, 4.2241e-01]],\n",
      "\n",
      "         [[8.5109e-01, 4.3125e-01, 9.1982e-01, 4.3355e-01],\n",
      "          [3.3164e-01, 4.2209e-01, 4.8226e-01, 1.6965e-01],\n",
      "          [8.9774e-01, 3.0105e-01, 6.9287e-01, 3.6080e-01]],\n",
      "\n",
      "         [[3.4375e-01, 5.6869e-01, 2.8446e-01, 6.2233e-01],\n",
      "          [5.1539e-01, 9.1653e-01, 8.0478e-01, 3.4516e-01],\n",
      "          [8.6642e-01, 9.3964e-01, 8.2994e-01, 8.7844e-01]],\n",
      "\n",
      "         [[7.3775e-01, 7.4217e-01, 8.2209e-01, 6.0524e-01],\n",
      "          [8.1850e-01, 9.2869e-01, 7.5210e-01, 8.9847e-01],\n",
      "          [2.5537e-02, 5.9295e-01, 5.6879e-01, 4.3612e-01]]]])\n",
      "tensor([[[[0, 1, 0, 0],\n",
      "          [0, 0, 1, 0],\n",
      "          [0, 0, 0, 1]],\n",
      "\n",
      "         [[0, 0, 0, 1],\n",
      "          [0, 0, 1, 0],\n",
      "          [0, 0, 0, 1]],\n",
      "\n",
      "         [[0, 0, 1, 0],\n",
      "          [0, 0, 0, 1],\n",
      "          [0, 0, 1, 0]],\n",
      "\n",
      "         [[0, 0, 1, 0],\n",
      "          [0, 0, 0, 1],\n",
      "          [0, 1, 0, 0]],\n",
      "\n",
      "         [[0, 1, 0, 0],\n",
      "          [1, 0, 0, 0],\n",
      "          [1, 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 0, 0, 0],\n",
      "          [0, 0, 1, 0],\n",
      "          [0, 1, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 1],\n",
      "          [0, 1, 0, 0],\n",
      "          [0, 0, 1, 0]],\n",
      "\n",
      "         [[0, 0, 1, 0],\n",
      "          [0, 0, 1, 0],\n",
      "          [1, 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0, 1],\n",
      "          [0, 1, 0, 0],\n",
      "          [0, 1, 0, 0]],\n",
      "\n",
      "         [[0, 0, 1, 0],\n",
      "          [0, 1, 0, 0],\n",
      "          [0, 1, 0, 0]]]])\n",
      "tensor([[[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
      "         [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand(2,5,3,4)\n",
    "am = torch.argmax(A,dim=-1)\n",
    "onehot = F.one_hot(am, num_classes=4)\n",
    "print(A)\n",
    "print(onehot)\n",
    "print(onehot.reshape(2,5,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdef3c49-439b-4eef-9459-81ae2773b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [1., 0., 0., 0.],\n",
      "          [0., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 1., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 1., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.],\n",
      "          [0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.],\n",
      "          [1., 0., 0., 0.],\n",
      "          [1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 1., 0., 0.]]]])\n",
      "tensor([[[0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "         [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand(2,5,3,4)\n",
    "gs = F.gumbel_softmax(A, tau=0.1, hard=True)\n",
    "print(gs)\n",
    "print(gs.reshape(2,5,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fb9eb1b-6178-4465-bc66-6d49a654e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 50, 8])\n"
     ]
    }
   ],
   "source": [
    "cnt = Controller(6,3,8,2)\n",
    "print(cnt(torch.rand(100,50,6)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2115129a-c942-433b-b19e-bcc375c2b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControllerFFN(nn.Module):\n",
    "    def __init__(self, dim_in, dim_lowrank, dim_hidden, num_blocks):\n",
    "        super(ControllerFFN, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_lowrank = dim_lowrank\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.num_blocks = num_blocks\n",
    "        assert self.dim_hidden % self.num_blocks == 0, \"hidden vector must be divisible into N blocks\"\n",
    "        self.controller = Controller(dim_in, dim_lowrank, dim_hidden, num_blocks)\n",
    "        self.layer1 = nn.Linear(dim_in, dim_hidden)\n",
    "        self.layer2 = nn.Linear(dim_hidden, dim_in)\n",
    "    def forward(self, x):\n",
    "        return self.layer2(self.controller(x)*self.layer1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aae9020-9cb0-4f81-854f-c4ca6b2b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 50, 6])\n"
     ]
    }
   ],
   "source": [
    "cntffn = ControllerFFN(6,3,8,2)\n",
    "print(cntffn(torch.rand(100,50,6)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d6e90-31c6-4ab9-a71b-82303563fd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
