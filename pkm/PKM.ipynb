{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b72a660b-85df-4474-abac-8c9c00dd11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d24138d-4b13-401c-9a3e-dcebcee7d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryNetwork(nn.Module):\n",
    "    def __init__(self, dim_in, dim_hidden, num_heads, batch_norm = True):\n",
    "        super(QueryNetwork, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.num_heads = num_heads\n",
    "        self.batch_norm = True\n",
    "        self.Wq = nn.Linear(dim_in, dim_hidden * num_heads, bias = False)\n",
    "        self.bn = nn.BatchNorm1d(dim_hidden * num_heads)\n",
    "    def forward(self, x):\n",
    "        # for memory of size less than 384*384 the paper says that batch norm gives no significant improvement\n",
    "        # when using batch norm, padding tokens in the sequence can skew mean and variance estimate\n",
    "        query = self.Wq(x)\n",
    "        \n",
    "        if self.batch_norm:\n",
    "            original_shape = query.shape\n",
    "            query = query.reshape(-1, self.dim_hidden * self.num_heads)\n",
    "            normalized = self.bn(query)\n",
    "            normalized = normalized.reshape(original_shape)\n",
    "            return normalized.reshape(*normalized.shape[:-1], self.num_heads, self.dim_hidden)\n",
    "        else:\n",
    "            return query.reshape(*query.shape[:-1], self.num_heads, self.dim_hidden) # batch size x context length x num heads x query dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f6c7dd-108b-4e97-82ca-40e24d05d09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10, 4, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn = QueryNetwork(7,5, 4)\n",
    "qn(torch.rand(100,10,7)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "918b4c9f-9c95-494f-8264-650fcbf36aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductKey(nn.Module):\n",
    "    def __init__(self, dim, num_subkeys, top_k, num_heads):\n",
    "        super(ProductKey, self).__init__()\n",
    "        assert dim % 2 == 0, \"key must be able to be split into 2\"\n",
    "        self.dim = dim\n",
    "        self.subkey_size = dim // 2\n",
    "        self.top_k = top_k\n",
    "        self.num_subkeys = num_subkeys\n",
    "        \n",
    "        keyl = torch.empty(num_heads, num_subkeys, self.subkey_size)\n",
    "        keyr = torch.empty(num_heads, num_subkeys, self.subkey_size)\n",
    "\n",
    "        std = 1/math.sqrt(dim)\n",
    "        keyl.uniform_(-std, std)\n",
    "        keyr.uniform_(-std, std)\n",
    "\n",
    "        self.keyl = nn.Parameter(keyl)\n",
    "        self.keyr = nn.Parameter(keyr)\n",
    "\n",
    "    def forward(self, query):\n",
    "        # multihead query\n",
    "        batch, context_length, num_heads, query_size = query.shape\n",
    "        \n",
    "        queryl = query[..., :self.subkey_size]\n",
    "        queryr = query[..., self.subkey_size:]\n",
    "\n",
    "        scorel = torch.einsum('bcnq,nkq->bcnk', queryl, self.keyl) # batch size x context length x num head x subquery length , num heads x num keys x subquery length\n",
    "        scorer = torch.einsum('bcnq,nkq->bcnk', queryr, self.keyr)\n",
    "\n",
    "        top_keys_l, top_idx_l = scorel.topk(self.top_k) # batch, context, heads, top k\n",
    "        top_keys_r, top_idx_r = scorer.topk(self.top_k)\n",
    "\n",
    "        #duplicate along the rows\n",
    "        product_scores_l = top_keys_l.reshape(*top_keys_l.shape[:-1], top_keys_l.shape[-1], 1).expand(*top_keys_l.shape[:-1], top_keys_l.shape[-1], top_keys_l.shape[-1])\n",
    "        # duplicate along the columns\n",
    "        product_scores_r = top_keys_r.reshape(*top_keys_r.shape[:-1], 1, top_keys_r.shape[-1]).expand(*top_keys_r.shape[:-1], top_keys_r.shape[-1], top_keys_r.shape[-1])\n",
    "\n",
    "        product_scores = (product_scores_l + product_scores_r) # batch, context, heads, top k, top k\n",
    "        product_scores = product_scores.reshape(batch, context_length, num_heads, self.top_k * self.top_k)\n",
    "\n",
    "        product_indices = top_idx_l.reshape(*top_idx_l.shape[:-1], top_idx_l.shape[-1], 1).expand(*top_idx_l.shape[:-1], top_idx_l.shape[-1], top_idx_l.shape[-1]) * self.num_subkeys\n",
    "        product_indices += top_idx_r.reshape(*top_idx_r.shape[:-1], top_idx_r.shape[-1], 1).expand(*top_idx_r.shape[:-1], top_idx_r.shape[-1], top_idx_r.shape[-1]) \n",
    "        product_indices = product_indices.reshape(batch, context_length, num_heads, self.top_k * self.top_k)\n",
    "\n",
    "        top_product_scores, top_product_indices = product_scores.topk(self.top_k)\n",
    "        selected_value_weights = F.softmax(top_product_scores, dim=-1)\n",
    "        selected_value_indices = torch.gather(product_indices, -1, top_product_indices)\n",
    "        #print(top_product_scores)\n",
    "        #print(torch.gather(product_scores, -1, top_product_indices)) # they should be equal\n",
    "        return selected_value_weights, selected_value_indices\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b9e3721-6d17-48df-b629-a084adebbb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1053, 0.8178, 0.5525, 0.3539],\n",
      "          [0.4601, 0.4129, 0.9341, 0.3508],\n",
      "          [0.3305, 0.7884, 0.3015, 0.9904]],\n",
      "\n",
      "         [[0.1591, 0.5620, 0.1787, 0.1385],\n",
      "          [0.9471, 0.3718, 0.5186, 0.1728],\n",
      "          [0.8403, 0.5152, 0.0786, 0.8085]]]])\n",
      "tensor([[[[0.1053, 0.8178],\n",
      "          [0.4601, 0.4129],\n",
      "          [0.3305, 0.7884]],\n",
      "\n",
      "         [[0.1591, 0.5620],\n",
      "          [0.9471, 0.3718],\n",
      "          [0.8403, 0.5152]]]])\n",
      "tensor([[[[0.5525, 0.3539],\n",
      "          [0.9341, 0.3508],\n",
      "          [0.3015, 0.9904]],\n",
      "\n",
      "         [[0.1787, 0.1385],\n",
      "          [0.5186, 0.1728],\n",
      "          [0.0786, 0.8085]]]])\n"
     ]
    }
   ],
   "source": [
    "block = torch.rand(1,2,3,4)\n",
    "print(block)\n",
    "print(block[...,:2])\n",
    "print(block[...,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9de3f4-8fc3-429d-b465-cd5e05b21be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3561],\n",
      "         [0.9040],\n",
      "         [0.2236],\n",
      "         [0.9060]],\n",
      "\n",
      "        [[0.8523],\n",
      "         [0.1579],\n",
      "         [0.4793],\n",
      "         [0.3675]]])\n",
      "tensor([[[0.3561, 0.3561, 0.3561, 0.3561],\n",
      "         [0.9040, 0.9040, 0.9040, 0.9040],\n",
      "         [0.2236, 0.2236, 0.2236, 0.2236],\n",
      "         [0.9060, 0.9060, 0.9060, 0.9060]],\n",
      "\n",
      "        [[0.8523, 0.8523, 0.8523, 0.8523],\n",
      "         [0.1579, 0.1579, 0.1579, 0.1579],\n",
      "         [0.4793, 0.4793, 0.4793, 0.4793],\n",
      "         [0.3675, 0.3675, 0.3675, 0.3675]]])\n",
      "tensor([[[0.3561, 0.9040, 0.2236, 0.9060],\n",
      "         [0.3561, 0.9040, 0.2236, 0.9060],\n",
      "         [0.3561, 0.9040, 0.2236, 0.9060],\n",
      "         [0.3561, 0.9040, 0.2236, 0.9060]],\n",
      "\n",
      "        [[0.8523, 0.1579, 0.4793, 0.3675],\n",
      "         [0.8523, 0.1579, 0.4793, 0.3675],\n",
      "         [0.8523, 0.1579, 0.4793, 0.3675],\n",
      "         [0.8523, 0.1579, 0.4793, 0.3675]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,4,1)\n",
    "print(a)\n",
    "print(a.expand(2,4,4))\n",
    "b = a.reshape(2,1,4)\n",
    "print(b.expand(2,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "399c87ad-2203-457b-bd89-a73fe2d0a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9406,  0.8643],\n",
      "          [ 0.1486,  0.1485],\n",
      "          [ 1.3653,  1.2828],\n",
      "          [ 0.5725,  0.5647]],\n",
      "\n",
      "         [[ 1.1675,  0.9089],\n",
      "          [ 0.0824, -0.0272],\n",
      "          [ 0.3099,  0.1507],\n",
      "          [ 0.2130,  0.1989]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4970,  0.3907],\n",
      "          [ 0.3884,  0.3348],\n",
      "          [-0.1141, -0.1393],\n",
      "          [ 0.4365,  0.1453]],\n",
      "\n",
      "         [[ 0.3047,  0.1988],\n",
      "          [ 0.7850,  0.7605],\n",
      "          [ 0.9413,  0.8459],\n",
      "          [ 0.4884,  0.4194]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8606,  0.8399],\n",
      "          [ 0.3752,  0.2896],\n",
      "          [ 2.5514,  2.4396],\n",
      "          [ 0.2540,  0.1578]],\n",
      "\n",
      "         [[ 1.0256,  0.6873],\n",
      "          [ 1.2209,  0.9314],\n",
      "          [ 1.2635,  1.1965],\n",
      "          [ 0.4429,  0.2562]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4367,  0.3870],\n",
      "          [ 0.8675,  0.8348],\n",
      "          [ 1.7378,  1.5173],\n",
      "          [ 0.5041,  0.4577]],\n",
      "\n",
      "         [[ 0.6319,  0.4495],\n",
      "          [ 0.1568,  0.1509],\n",
      "          [-0.0641, -0.1277],\n",
      "          [ 0.6859,  0.2412]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0164, -0.0405],\n",
      "          [ 0.8806,  0.8216],\n",
      "          [-0.0587, -0.1150],\n",
      "          [ 1.8261,  1.7571]],\n",
      "\n",
      "         [[ 0.1275,  0.1055],\n",
      "          [ 0.4726,  0.3700],\n",
      "          [ 1.3724,  1.2634],\n",
      "          [ 0.5831,  0.3277]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0775,  0.0742],\n",
      "          [ 0.4330,  0.1387],\n",
      "          [ 1.0325,  0.4593],\n",
      "          [ 0.2037,  0.0958]],\n",
      "\n",
      "         [[ 0.7193,  0.5532],\n",
      "          [ 0.8008,  0.6440],\n",
      "          [ 0.7569,  0.5654],\n",
      "          [ 1.1721,  0.4731]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3222,  0.3129],\n",
      "          [ 0.7712,  0.7683],\n",
      "          [ 1.0508,  0.6690],\n",
      "          [ 2.1417,  1.9135]],\n",
      "\n",
      "         [[ 0.3902,  0.3054],\n",
      "          [ 0.6536,  0.2317],\n",
      "          [-0.0841, -0.1019],\n",
      "          [ 0.9331,  0.9164]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3997,  0.3379],\n",
      "          [ 0.5021,  0.4168],\n",
      "          [ 0.4497,  0.2751],\n",
      "          [ 1.2964,  0.7696]],\n",
      "\n",
      "         [[ 0.5598,  0.4394],\n",
      "          [ 0.7844,  0.4744],\n",
      "          [ 1.1219,  1.0976],\n",
      "          [ 0.7728,  0.3859]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2202,  0.1660],\n",
      "          [ 0.6925,  0.5704],\n",
      "          [-0.4943, -0.5171],\n",
      "          [ 1.6029,  0.8219]],\n",
      "\n",
      "         [[ 0.3507,  0.3332],\n",
      "          [ 0.0497,  0.0462],\n",
      "          [ 0.1036, -0.1940],\n",
      "          [ 1.4342,  0.8902]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1380,  0.0289],\n",
      "          [ 0.6342,  0.4993],\n",
      "          [ 1.0190,  0.9491],\n",
      "          [ 0.8144,  0.6635]],\n",
      "\n",
      "         [[ 0.1453,  0.1103],\n",
      "          [ 0.2906,  0.1713],\n",
      "          [-0.0465, -0.3792],\n",
      "          [ 0.7924,  0.7072]]]], grad_fn=<TopkBackward0>)\n",
      "tensor([[[[ 0.9406,  0.8643],\n",
      "          [ 0.1486,  0.1485],\n",
      "          [ 1.3653,  1.2828],\n",
      "          [ 0.5725,  0.5647]],\n",
      "\n",
      "         [[ 1.1675,  0.9089],\n",
      "          [ 0.0824, -0.0272],\n",
      "          [ 0.3099,  0.1507],\n",
      "          [ 0.2130,  0.1989]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4970,  0.3907],\n",
      "          [ 0.3884,  0.3348],\n",
      "          [-0.1141, -0.1393],\n",
      "          [ 0.4365,  0.1453]],\n",
      "\n",
      "         [[ 0.3047,  0.1988],\n",
      "          [ 0.7850,  0.7605],\n",
      "          [ 0.9413,  0.8459],\n",
      "          [ 0.4884,  0.4194]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8606,  0.8399],\n",
      "          [ 0.3752,  0.2896],\n",
      "          [ 2.5514,  2.4396],\n",
      "          [ 0.2540,  0.1578]],\n",
      "\n",
      "         [[ 1.0256,  0.6873],\n",
      "          [ 1.2209,  0.9314],\n",
      "          [ 1.2635,  1.1965],\n",
      "          [ 0.4429,  0.2562]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4367,  0.3870],\n",
      "          [ 0.8675,  0.8348],\n",
      "          [ 1.7378,  1.5173],\n",
      "          [ 0.5041,  0.4577]],\n",
      "\n",
      "         [[ 0.6319,  0.4495],\n",
      "          [ 0.1568,  0.1509],\n",
      "          [-0.0641, -0.1277],\n",
      "          [ 0.6859,  0.2412]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0164, -0.0405],\n",
      "          [ 0.8806,  0.8216],\n",
      "          [-0.0587, -0.1150],\n",
      "          [ 1.8261,  1.7571]],\n",
      "\n",
      "         [[ 0.1275,  0.1055],\n",
      "          [ 0.4726,  0.3700],\n",
      "          [ 1.3724,  1.2634],\n",
      "          [ 0.5831,  0.3277]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0775,  0.0742],\n",
      "          [ 0.4330,  0.1387],\n",
      "          [ 1.0325,  0.4593],\n",
      "          [ 0.2037,  0.0958]],\n",
      "\n",
      "         [[ 0.7193,  0.5532],\n",
      "          [ 0.8008,  0.6440],\n",
      "          [ 0.7569,  0.5654],\n",
      "          [ 1.1721,  0.4731]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3222,  0.3129],\n",
      "          [ 0.7712,  0.7683],\n",
      "          [ 1.0508,  0.6690],\n",
      "          [ 2.1417,  1.9135]],\n",
      "\n",
      "         [[ 0.3902,  0.3054],\n",
      "          [ 0.6536,  0.2317],\n",
      "          [-0.0841, -0.1019],\n",
      "          [ 0.9331,  0.9164]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3997,  0.3379],\n",
      "          [ 0.5021,  0.4168],\n",
      "          [ 0.4497,  0.2751],\n",
      "          [ 1.2964,  0.7696]],\n",
      "\n",
      "         [[ 0.5598,  0.4394],\n",
      "          [ 0.7844,  0.4744],\n",
      "          [ 1.1219,  1.0976],\n",
      "          [ 0.7728,  0.3859]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2202,  0.1660],\n",
      "          [ 0.6925,  0.5704],\n",
      "          [-0.4943, -0.5171],\n",
      "          [ 1.6029,  0.8219]],\n",
      "\n",
      "         [[ 0.3507,  0.3332],\n",
      "          [ 0.0497,  0.0462],\n",
      "          [ 0.1036, -0.1940],\n",
      "          [ 1.4342,  0.8902]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1380,  0.0289],\n",
      "          [ 0.6342,  0.4993],\n",
      "          [ 1.0190,  0.9491],\n",
      "          [ 0.8144,  0.6635]],\n",
      "\n",
      "         [[ 0.1453,  0.1103],\n",
      "          [ 0.2906,  0.1713],\n",
      "          [-0.0465, -0.3792],\n",
      "          [ 0.7924,  0.7072]]]], grad_fn=<GatherBackward0>)\n"
     ]
    }
   ],
   "source": [
    "qn = QueryNetwork(7,6, 4)\n",
    "query = qn(torch.rand(10,2,7))\n",
    "#print(query.shape)\n",
    "key = ProductKey(6, 3, 2, 4)\n",
    "key(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fdba940-bcfa-4049-b800-6556ad16cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PKM(nn.Module):\n",
    "    def __init__(self, dim_in, dim_hidden, num_subkeys, top_k, num_heads, batch_norm = True):\n",
    "        super(PKM, self).__init__()\n",
    "        self.dim_in, self.dim_hidden, self.num_subkeys, self.top_k, self.num_heads = dim_in, dim_hidden, num_subkeys, top_k, num_heads\n",
    "        self.query_network = QueryNetwork(dim_in, dim_hidden, num_heads, batch_norm)\n",
    "        self.key_table = ProductKey(dim_hidden, num_subkeys, top_k, num_heads)\n",
    "        self.value_table = nn.Embedding(num_subkeys * num_subkeys, dim_in)\n",
    "    def forward(self, x):\n",
    "        queries = self.query_network(x)\n",
    "        weights, indices = self.key_table(queries) # shape is batch, context length, num heads, top k\n",
    "        original_shape = weights.shape\n",
    "        \n",
    "        weights, indices = weights.reshape(-1, self.top_k), indices.reshape(-1, self.top_k)\n",
    "        values = self.value_table(indices)\n",
    "        weights = weights.reshape(original_shape)\n",
    "        values = values.reshape(*original_shape, self.dim_in)\n",
    "\n",
    "        weighted_values = torch.einsum('bcnk,bcnkd->bcd', weights, values) # take linear combination of weights & values and sum over all heads\n",
    "\n",
    "        return weighted_values\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "668ab7a3-c375-4de3-9874-cd433f2a036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.4671, -1.9806, -1.0823, -1.2092, -6.0788],\n",
       "         [-1.9874, -1.2526, -0.0125, -0.1405,  1.1630],\n",
       "         [-4.6440,  1.8096, -2.4216, -0.6242, -4.7508],\n",
       "         [-0.6805, -0.1313, -3.2581, -5.1318, -0.4604]],\n",
       "\n",
       "        [[ 1.7440,  0.5148, -1.8089, -4.4855, -2.7130],\n",
       "         [-0.9145,  0.6873,  3.1486, -1.0154, -1.3887],\n",
       "         [-0.9262, -0.1986,  2.8402, -0.4718,  0.1240],\n",
       "         [ 1.3452,  1.8757, -2.3615,  0.9435, -0.7127]],\n",
       "\n",
       "        [[ 1.6607, -0.0710, -1.3316, -0.3714, -0.1003],\n",
       "         [ 1.7431, -0.3094, -3.9427, -3.6363, -3.9978],\n",
       "         [-0.1268,  0.2422,  0.2941, -0.8417, -2.8110],\n",
       "         [-3.6644,  1.7039,  2.1051, -1.0184, -1.6720]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkm = PKM(5,8,10,2,4)\n",
    "pkm(torch.rand(3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f38c08-bc82-47bd-98fc-7c39a50bb620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
